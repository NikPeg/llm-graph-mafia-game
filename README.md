# GraphEnhancedLLMGame

Проект исследует применение графовых методов для улучшения игровых стратегий языковых моделей в социальной дедуктивной игре типа "Мафия".
Сравниваются различные техники инжектирования графов (коммуникационных, профильных, исторических) для преодоления ограничений контекстного окна и улучшения принятия решений в условиях неполной информации.
---

## Быстрый старт

> **Внимание:** для запуска проекта требуется производительная видеокарта (например, NVIDIA A100 или мощнее), так как все симуляции работают с большими локальными LLM.
### 1. Запуск LLM-сервера

Для запуска используйте скрипт [`run_llm.sh`](./run_llm.sh).  
Он стартует vllm-сервер с вашей моделью.

**Пример:**
```bash
# Запустить с моделью по умолчанию (gryphe/mythomax-l2-13b)
./run_llm.sh

# Или указать другую поддерживаемую модель, например:
./run_llm.sh mistralai/mistral-small-24b-instruct-2501
```
Логи работы сервера пишутся в `vllm.log`.

---

### 2. Запуск симуляции

Основной скрипт — [`src/simulate.py`](./src/simulate.py).  
Он запускает серию игр в мафию между LLM-агентами-клонами.

**Пример:**
```bash
python3 src/simulate.py
```
По умолчанию используются параметры из `src/config.py`, включая количество игр, количество участников, роль модели и т.д.

---

### 3. Конфигурация

- Все настройки (количество игроков, список доступных моделей, имя используемой модели) — в файле [`src/config.py`](./src/config.py).
- Модель для симуляции указывается:
    - Аргументом для `run_llm.sh`
    - Или переменной окружения `MODEL_NAME`
    - Или прямо в `config.py`

---

### 4. Логи и вывод

- После симуляции вы увидите подробные игровые логи, выборы, распределение ролей, анализ критика по итогам каждой партии.
- Итоговая статистика: кто чаще выигрывает (мафия или мирные).
- Дополнительно можно изучить графы отношений LLM-игроков для гипотез и анализа стратегии.

---

## Доступные модели

(см. полный список в `src/config.py`)
Примеры:
- `gryphe/mythomax-l2-13b` (по умолчанию)
- `mistralai/mistral-small-24b-instruct-2501`
- `deepseek/deepseek-llm-7b-chat`
- `deepseek/deepseek-r1-distill-llama-70b`
- `nousresearch/hermes-3-llama-3.1-70b`
- `deepseek-ai/DeepSeek-R1-Distill-Qwen-32B`
---

## Описание структуры

- `run_llm.sh` — скрипт запуска локального LLM-сервера (vllm)
- `src/simulate.py` — симуляция игр в мафию
- `src/config.py` — основные параметры и список моделей

---

## Варианты использования

- Исследование динамики коллективного принятия решений LLM'ами
- Тестирование новых моделей на "детективном" поведении
- Валидация/разработка автоматических метрик доверия к генеративным агентам
- Быстрая отладка игровых циклов для собственных LLM и промпт-инженерии

---

## Частые вопросы

- **Q:** Нужно ли что-то кроме Python и vllm?  
  **A:** Нет. Библиотека vllm для сервера + зависимости из requirements.txt.

- **Q:** Можно ли проводить эксперименты с несколькими моделями?  
  **A:** В текущем коде поддержан выбор одной используемой модели на запуск.

- **Q:** Где анализировать поведение агентов и результаты партий?  
  **A:** В логах симуляции и итоговом выводе статистики по ролям.

---

## Рекомендации

- Используйте одновременный запуск vllm только с ОДНОЙ моделью на сервер (ограничение проекта).
- Для ускоренной симуляции или повышения сложности меняйте роли и параметры в config.py.
- Графы отношений и внутриигровые решения — отличное поле для экспериментов с интерпретацией поведения LLM.

---

## Результаты

| Модель                                      | Без графа | Коммуникационный граф | Комм. граф с историей | Граф текущего раунда | Граф текущ. раунда с историей | Глобальный граф | Глобальный граф с историей |
|----------------------------------------------|-----------|----------------------|-----------------------|----------------------|-------------------------------|-----------------|----------------------------|
| gryphe/mythomax-l2-13b                      |    41     |         37           |          48           |          39          | 50                            |       38        | 55                         |
| mistralai/mistral-small-24b-instruct-2501    |    39     |         36           |          47           |          38          | 49                            |       37        | 56                         |
| deepseek/deepseek-llm-7b-chat                |    40     |         35           |          45           |          38          | 47                            |       36        | 54                         |
| deepseek/deepseek-r1-distill-llama-70b       |    42     |         38           |          49           |          39          | **51**                        |       37        | **58**                     |
| nousresearch/hermes-3-llama-3.1-70b          |    41     |         36           |          46           |          40          | 48                            |       38        | 55                         |
| deepseek-ai/DeepSeek-R1-Distill-Qwen-32B     |    40     |         35           |          46           |          39          | 48                            |       36        | 54                         |

В ячейках указано количество побед мирных игроков из 80 игр.

---

## Контакты

- Автор и вопросы: t.me/nikpeg